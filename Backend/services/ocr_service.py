from easyocr import Reader            # OCR ì²˜ë¦¬ë¥¼ ìœ„í•œ EasyOCR
from fugashi import Tagger           # ì¼ë³¸ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸°
from pykakasi import kakasi          # í•œì â†’ íˆë¼ê°€ë‚˜ ë³€í™˜ê¸°
from PIL import Image                # ì´ë¯¸ì§€ ì²˜ë¦¬ìš©
import numpy as np
import torch
import re
from io import BytesIO
from typing import Dict, List
from googletrans import Translator   # ì˜ì–´ ë²ˆì—­ê¸°

from schemas import OCRWord                    # ğŸ“Œ ê³µí†µ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ

# âœ… OCR ë° í…ìŠ¤íŠ¸ ë³€í™˜ê¸° ì´ˆê¸°í™”
USE_GPU = torch.cuda.is_available()
print(f"âœ… GPU ì‚¬ìš© ì—¬ë¶€: {USE_GPU}")

reader = Reader(['ja'], gpu=USE_GPU)  # ì¼ë³¸ì–´ OCR,
tagger = Tagger()                   # í˜•íƒœì†Œ ë¶„ì„ê¸°
translator = Translator()           # êµ¬ê¸€ ë²ˆì—­ê¸°

# ë³€í™˜ê¸° ì„¤ì • (ëª¨ë‘ íˆë¼ê°€ë‚˜ë¡œ ë³€í™˜)
kakasi_converter = kakasi()
kakasi_converter.setMode("J", "H")  # í•œì â†’ íˆë¼ê°€ë‚˜
kakasi_converter.setMode("K", "H")  # ê°€íƒ€ì¹´ë‚˜ â†’ íˆë¼ê°€ë‚˜
kakasi_converter.setMode("H", "H")  # íˆë¼ê°€ë‚˜ â†’ íˆë¼ê°€ë‚˜ (ìœ ì§€)
kakasi_converter.setMode("r", "Hepburn")  # ë¡œë§ˆì ì¶œë ¥ ë°©ì‹
conv = kakasi_converter.getConverter()


def contains_kanji(text: str) -> bool:
    """ğŸ“Œ í•œìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ì •ê·œì‹ ê²€ì‚¬"""
    return bool(re.search(r'[\u4e00-\u9faf]', text))


def extract_japanese_from_image(image_bytes: bytes) -> str:
    """
    ğŸ“Œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - OCR ìˆ˜í–‰ í›„ í•œì í¬í•¨ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
    """
    image = Image.open(BytesIO(image_bytes)).convert("RGB")
    image_np = np.array(image)
    ocr_results = reader.readtext(image_np, detail=0)  # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ

    japanese_lines = [text for text in ocr_results if contains_kanji(text)]
    return ''.join(japanese_lines)


def make_vocabulary(image_bytes: bytes) -> List[OCRWord]:
    """
    ğŸ“Œ ì¼ë³¸ì–´ ì´ë¯¸ì§€ì—ì„œ ë‹¨ì–´ì¥ ìƒì„±
    - OCR â†’ í˜•íƒœì†Œ ë¶„ì„ â†’ íˆë¼ê°€ë‚˜ ë³€í™˜ â†’ ì¤‘ë³µ ì œê±°
    """
    text = extract_japanese_from_image(image_bytes)
    seen = set()
    result = []

    for word in tagger(text):
        surface = word.surface

        if surface not in seen and contains_kanji(surface):
            seen.add(surface)
            reading = conv.do(surface)
            result.append(OCRWord(word=surface, reading=reading))

    return result


def add_translation(vocabulary: List[OCRWord]) -> List[dict]:
    """
    ğŸ“Œ ë‹¨ì–´ ëª©ë¡ì— ì˜ì–´ ë²ˆì—­ ì¶”ê°€
    - OCRWord ëª©ë¡ì— ëŒ€í•´ ë²ˆì—­ëœ dict ë°˜í™˜
    """
    new_vocabulary = []

    for w in vocabulary:
        try:
            result = translator.translate(w.word, src="ja", dest="en")
            translated = result.text if result and hasattr(
                result, "text") else ""
        except Exception as e:
            print(f"âŒ Translation failed for {w.word}: {e}")
            translated = ""

        new_vocabulary.append({
            "word": w.word,
            "reading": w.reading,
            "translation": translated
        })

    return new_vocabulary


def make_furigana(image_bytes: bytes) -> str:
    """
    ğŸ“Œ ë¬¸ì¥ ë‚´ í•œìì— íˆë¼ê°€ë‚˜ ì‚½ì…, íˆë¼ê°€ë‚˜ ë§Œë“¤ê¸°
    - ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ í¬í•¨
    - ì˜ˆ: æ—¥æœ¬èª â†’ æ—¥æœ¬èª(ã«ã»ã‚“ã”)
    """
    #  OCR ì¸ì‹
    text = extract_japanese_from_image(image_bytes)
    #  ì •ê·œí™”
    text = text.replace(";", "ã€").replace(",", "ã€").replace(".", "ã€‚")
    #  íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r"[^\u3040-\u30FF\u4E00-\u9FAFã€‚ã€0-9a-zA-Z\s]", "", text)
    #  ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• 
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', text)

    result = []
    for sentence in sentences:
        if sentence.strip() == "":
            continue

        sentence_result = []
        for word in tagger(sentence):
            surface = word.surface
            if surface.strip() == "":
                continue
            if re.search(r'[\u4e00-\u9faf]', surface):
                reading = conv.do(surface)
                sentence_result.append(f"{surface}({reading})")
            else:
                sentence_result.append(surface)

        result.append(''.join(sentence_result).strip())

    # ë¬¸ì¥ ë‹¨ìœ„ ì¤„ë°”ê¿ˆ ë°˜í™˜
    return '\n'.join(result)
